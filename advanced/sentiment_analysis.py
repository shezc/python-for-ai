"""
Transformers æƒ…æ„Ÿåˆ†æç¤ºä¾‹
ä½¿ç”¨ Hugging Face Transformers è¿›è¡Œæ–‡æœ¬æƒ…æ„Ÿåˆ†æ

æ¨¡å‹å·²ä¸‹è½½åˆ°æœ¬åœ°ï¼Œä»æœ¬åœ°è·¯å¾„åŠ è½½ä½¿ç”¨ï¼Œæ— éœ€ç½‘ç»œè¿æ¥
"""

import os
from pathlib import Path

# é…ç½®æœ¬åœ°æ¨¡å‹å­˜å‚¨ç›®å½• - Cç›˜æ ¹ç›®å½•ä¸‹çš„modelsæ–‡ä»¶å¤¹
MODELS_DIR = Path("C:/models")
MODELS_DIR.mkdir(parents=True, exist_ok=True)

# æ¨¡å‹é…ç½®
MODEL_CONFIGS = {
    "chinese": {
        "name": "uer/roberta-base-finetuned-chinanews-chinese",
        "local_path": MODELS_DIR / "chinese-sentiment",
        "display_name": "ä¸­æ–‡æƒ…æ„Ÿåˆ†ææ¨¡å‹"
    },
    "english": {
        "name": "distilbert-base-uncased-finetuned-sst-2-english",
        "local_path": MODELS_DIR / "english-sentiment",
        "display_name": "è‹±æ–‡æƒ…æ„Ÿåˆ†ææ¨¡å‹"
    }
}

# è‡ªåŠ¨é…ç½®é•œåƒç«™ï¼ˆå¦‚æœæœªè®¾ç½®ç¯å¢ƒå˜é‡ï¼‰
MIRROR_ENDPOINT = 'https://hf-mirror.com'
if 'HF_ENDPOINT' not in os.environ:
    os.environ['HF_ENDPOINT'] = MIRROR_ENDPOINT

# è®¾ç½®ä¸‹è½½è¶…æ—¶ï¼ˆå¯é€‰ï¼Œå•ä½ï¼šç§’ï¼‰
# å¦‚æœç½‘ç»œè¾ƒæ…¢ï¼Œå¯ä»¥å¢åŠ è¿™ä¸ªå€¼
if 'HF_HUB_DOWNLOAD_TIMEOUT' not in os.environ:
    os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '300'  # 5åˆ†é’Ÿè¶…æ—¶

from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import torch


def download_model(model_key="chinese", force_download=False):
    """
    ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
    
    Args:
        model_key: æ¨¡å‹é”®å ("chinese" æˆ– "english")
        force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
    """
    if model_key not in MODEL_CONFIGS:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹é”®: {model_key}")
    
    config = MODEL_CONFIGS[model_key]
    local_path = config["local_path"]
    model_name = config["name"]
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
    if local_path.exists() and not force_download:
        print(f"âœ… {config['display_name']} å·²å­˜åœ¨äºæœ¬åœ°: {local_path}")
        return str(local_path)
    
    print(f"\nğŸ“¥ æ­£åœ¨ä¸‹è½½ {config['display_name']}...")
    print(f"   æ¨¡å‹: {model_name}")
    print(f"   ä¿å­˜åˆ°: {local_path}")
    print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...\n")
    
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        local_path.mkdir(parents=True, exist_ok=True)
        
        # ä¸‹è½½æ¨¡å‹å’Œåˆ†è¯å™¨ï¼ˆå…ˆä¸‹è½½åˆ°ä¸´æ—¶ä½ç½®ï¼Œç„¶åä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ï¼‰
        print("   æ­£åœ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
        # æ³¨æ„: from_pretrained ä¸æ”¯æŒ timeout å‚æ•°
        # è¶…æ—¶è®¾ç½®éœ€è¦é€šè¿‡ç¯å¢ƒå˜é‡ HF_HUB_DOWNLOAD_TIMEOUT æˆ– requests åº“é…ç½®
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        
        # ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        print("   æ­£åœ¨ä¿å­˜åˆ°æœ¬åœ°...")
        tokenizer.save_pretrained(str(local_path))
        model.save_pretrained(str(local_path))
        
        print(f"âœ… {config['display_name']} ä¸‹è½½å®Œæˆï¼")
        print(f"   ä¿å­˜ä½ç½®: {local_path}\n")
        
        return str(local_path)
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        print("\næç¤º:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. å¦‚æœä½¿ç”¨é•œåƒï¼Œç¡®ä¿ HF_ENDPOINT ç¯å¢ƒå˜é‡å·²è®¾ç½®")
        print("3. å¯ä»¥æ‰‹åŠ¨è®¾ç½®é•œåƒ: os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'")
        raise


def get_model_path(model_key="chinese", auto_download=True):
    """
    è·å–æ¨¡å‹æœ¬åœ°è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½
    
    Args:
        model_key: æ¨¡å‹é”®å
        auto_download: å¦‚æœæ¨¡å‹ä¸å­˜åœ¨æ˜¯å¦è‡ªåŠ¨ä¸‹è½½
    """
    config = MODEL_CONFIGS[model_key]
    local_path = config["local_path"]
    
    if local_path.exists():
        return str(local_path)
    elif auto_download:
        return download_model(model_key)
    else:
        raise FileNotFoundError(
            f"æ¨¡å‹ä¸å­˜åœ¨äº {local_path}ï¼Œè¯·å…ˆè¿è¡Œ download_model('{model_key}') ä¸‹è½½æ¨¡å‹"
        )


def basic_sentiment_analysis():
    """åŸºæœ¬æƒ…æ„Ÿåˆ†æç¤ºä¾‹ï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰"""
    print("=" * 60)
    print("1. åŸºæœ¬æƒ…æ„Ÿåˆ†æï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰")
    print("=" * 60)
    
    try:
        # è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆå¦‚æœä¸å­˜åœ¨ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
        model_path = get_model_path("chinese", auto_download=True)
        
        # ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹
        classifier = pipeline("sentiment-analysis", model=model_path)
        
        print(f"classifier.model.config.id2label: {classifier.model.config.id2label}")

        # æµ‹è¯•æ–‡æœ¬
        texts = [
            "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œå¿ƒæƒ…å¾ˆæ„‰å¿«ï¼",
            "è¿™éƒ¨ç”µå½±å¤ªç³Ÿç³•äº†ï¼Œå®Œå…¨ä¸å€¼å¾—çœ‹ã€‚",
            "äº§å“è¿˜ä¸é”™ï¼Œä½†ä»·æ ¼æœ‰ç‚¹è´µã€‚",
            "æœåŠ¡æ€åº¦å¾ˆå¥½ï¼Œæ¨èå¤§å®¶æ¥è¯•è¯•ã€‚",
            "ä¸­å›½è¶³çƒæˆ˜èƒœäº†å·´è¥¿ç”·è¶³"
        ]
        
        print("\nåˆ†æç»“æœï¼š")
        for text in texts:
            result = classifier(text)
            label = result[0]['label']
            score = result[0]['score']
            
            # è½¬æ¢æ ‡ç­¾ä¸ºä¸­æ–‡
            print(f"result: {result[0]}")
            label_cn = "æ­£é¢" if label == "POSITIVE" else "è´Ÿé¢"
            
            print(f"\næ–‡æœ¬: {text}")
            print(f"  æƒ…æ„Ÿ: {label_cn}")
            print(f"  ç½®ä¿¡åº¦: {score:.4f}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
    
    print("\n" + "=" * 60 + "\n")


def batch_sentiment_analysis():
    """æ‰¹é‡æƒ…æ„Ÿåˆ†æç¤ºä¾‹ï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰"""
    print("=" * 60)
    print("3. æ‰¹é‡æƒ…æ„Ÿåˆ†æï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰")
    print("=" * 60)
    
    try:
        # è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„
        model_path = get_model_path("chinese", auto_download=True)
        
        # ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹
        classifier = pipeline("sentiment-analysis", model=model_path)
        
        # æ‰¹é‡æ–‡æœ¬
        texts = [
            "è¿™ä¸ªé¤å…çš„èœå“éå¸¸ç¾å‘³ï¼Œç¯å¢ƒä¹Ÿå¾ˆä¼˜é›…ã€‚",
            "å¿«é€’å¤ªæ…¢äº†ï¼Œç­‰äº†æ•´æ•´ä¸€å‘¨æ‰æ”¶åˆ°ã€‚",
            "å®¢æœå›å¤å¾ˆå¿«ï¼Œé—®é¢˜è§£å†³å¾—å¾ˆåŠæ—¶ã€‚",
            "äº§å“è´¨é‡ä¸€èˆ¬ï¼Œæ€§ä»·æ¯”ä¸é«˜ã€‚",
            "éå¸¸æ»¡æ„ï¼Œä¼šå†æ¬¡è´­ä¹°ï¼"
        ]
        
        print("\næ‰¹é‡åˆ†æç»“æœï¼š")
        # æ‰¹é‡å¤„ç†ï¼ˆæ›´é«˜æ•ˆï¼‰
        results = classifier(texts)
        
        for text, result in zip(texts, results):
            label = result['label']
            score = result['score']
            label_cn = "æ­£é¢" if label == "POSITIVE" else "è´Ÿé¢"
            
            print(f"\næ–‡æœ¬: {text}")
            print(f"  æƒ…æ„Ÿ: {label_cn} (ç½®ä¿¡åº¦: {score:.4f})")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
    
    print("\n" + "=" * 60 + "\n")


def detailed_sentiment_analysis():
    """è¯¦ç»†çš„æƒ…æ„Ÿåˆ†æï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰"""
    print("=" * 60)
    print("4. è¯¦ç»†æƒ…æ„Ÿåˆ†æï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œè·å–åŸå§‹åˆ†æ•°ï¼‰")
    print("=" * 60)
    
    try:
        # è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„
        model_path = get_model_path("chinese", auto_download=True)
        
        # ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹
        classifier = pipeline("sentiment-analysis", 
                             model=model_path,
                             top_k=None)  # è¿”å›æ‰€æœ‰ç±»åˆ«çš„åˆ†æ•°
        
        texts = [
            "è¿™ä¸ªç”µå½±å¤ªç²¾å½©äº†ï¼",
            "æœåŠ¡æ€åº¦å¾ˆå·®ï¼Œä¸æ¨èã€‚"
        ]
        
        print("\nè¯¦ç»†åˆ†æç»“æœï¼š")
        for text in texts:
            try:
                results = classifier(text)
                print(f"\næ–‡æœ¬: {text}")
                
                # å¤„ç†è¿”å›ç»“æœï¼štop_k=None æ—¶è¿”å›æ ¼å¼ä¸º [[{...}, {...}]]
                # å•ä¸ªæ–‡æœ¬æ—¶ï¼Œresults æ˜¯ [[{label: 'POSITIVE', score: 0.9}, {label: 'NEGATIVE', score: 0.1}]]
                if isinstance(results, list):
                    # è·å–ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ªï¼‰æ–‡æœ¬çš„æ‰€æœ‰ç»“æœ
                    if len(results) > 0 and isinstance(results[0], list):
                        text_results = results[0]
                    else:
                        text_results = results
                    
                    # æ˜¾ç¤ºæ‰€æœ‰ç±»åˆ«çš„åˆ†æ•°
                    for result in text_results:
                        if isinstance(result, dict):
                            label = result.get('label', 'UNKNOWN')
                            score = result.get('score', 0.0)
                            label_cn = "æ­£é¢" if label == "POSITIVE" else "è´Ÿé¢"
                            print(f"  {label_cn}: {score:.4f}")
                        else:
                            print(f"  ç»“æœæ ¼å¼å¼‚å¸¸: {result}")
                else:
                    print(f"  æ— æ³•è§£æç»“æœç±»å‹: {type(results)}")
            except Exception as e:
                print(f"\næ–‡æœ¬: {text}")
                print(f"  âŒ å¤„ç†å‡ºé”™: {e}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
    
    print("\n" + "=" * 60 + "\n")


def download_all_models():
    """ä¸‹è½½æ‰€æœ‰æ¨¡å‹åˆ°æœ¬åœ°"""
    print("\n" + "=" * 60)
    print("ä¸‹è½½æ‰€æœ‰æ¨¡å‹åˆ°æœ¬åœ°")
    print("=" * 60)
    print(f"\næ¨¡å‹ä¿å­˜ç›®å½•: {MODELS_DIR}\n")
    
    for model_key in MODEL_CONFIGS.keys():
        try:
            download_model(model_key, force_download=False)
        except Exception as e:
            print(f"âŒ ä¸‹è½½ {model_key} æ¨¡å‹å¤±è´¥: {e}\n")
    
    print("=" * 60)
    print("æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
    print("=" * 60 + "\n")


def demo():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("Transformers æƒ…æ„Ÿåˆ†æç¤ºä¾‹ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰")
    print("=" * 60)
    
    # æ˜¾ç¤ºæ¨¡å‹ç›®å½•
    print(f"\nğŸ“ æœ¬åœ°æ¨¡å‹ç›®å½•: {MODELS_DIR}")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    chinese_exists = MODEL_CONFIGS["chinese"]["local_path"].exists()
    english_exists = MODEL_CONFIGS["english"]["local_path"].exists()
    
    print(f"\næ¨¡å‹çŠ¶æ€:{'âœ… å·²ä¸‹è½½' if chinese_exists else 'âŒ æœªä¸‹è½½'}")
    
    if not chinese_exists or not english_exists:
        print("\nğŸ’¡ æç¤º: é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹")
        print("   ä¹Ÿå¯ä»¥æ‰‹åŠ¨è¿è¡Œ download_all_models() é¢„å…ˆä¸‹è½½æ‰€æœ‰æ¨¡å‹\n")
    
    try:
        # åŸºæœ¬æƒ…æ„Ÿåˆ†æ
        basic_sentiment_analysis()
        
        # æ‰¹é‡åˆ†æ
        # batch_sentiment_analysis()
        
        # è¯¦ç»†åˆ†æ
        # detailed_sentiment_analysis()
        
        print("\nâœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡ä¸‹è½½éœ€è¦ç½‘ç»œï¼‰")
        print("2. å®‰è£…å¿…è¦çš„ä¾èµ–: pip install transformers torch")
        print("3. å¦‚æœç½‘ç»œé—®é¢˜ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹")
        print("4. æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³")


if __name__ == "__main__":
    import sys
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1 and sys.argv[1] == "download":
        # ä¸‹è½½æ‰€æœ‰æ¨¡å‹
        download_all_models()
    else:
        # è¿è¡Œç¤ºä¾‹
        demo()

